---
layout: default
title: The Birth of BirdStatsGPT
parent: Storytime
nav_order: 6
---

# The Birth of BirdStatsGPT

The obvious next natural step is to build a system that is combining both the object seen and the sound heard, and connecting them in real time. But we haven't crossed that bridge yet, and it's actually incredibly hard to directionalize microphones with that cardioid pattern and level of sensitivity. 

Anyway, last thing on birds, I did make a model context protocol server and a custom GPT that I think is really cool. Since the eBird database and the database where you can upload your BirdNetPi data, which is something called BirdWeather.app, they're both kind of convoluted and difficult to go through in their own ways, so wouldn't it be nice to just query in natural language to compare the two for use cases like, "Hey, so my BirdNetPi said it heard a cedar waxwing this morning. They're not very common around here. Have other people near me reported seeing them on eBird recently?" Stuff like that. Or "Make me a seasonal migration analysis of my top ten bird species over the last two years." Or even comparing your station with other stations in your area. Possibilities for analysis and visualization are pretty endless when you have upwards of a million data points a year, which is what I typically have.

[Next: Accidental Enterprise AI](accidental_enterprise_ai.html)
